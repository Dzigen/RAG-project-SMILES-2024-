{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/home/team06/workspace/mikhail_workspace/mikhail_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "#BASE_DIR = \"/home/dzigen/Desktop/ITMO/smiles2024/RAG-project-SMILES-2024-\"\n",
    "BASE_DIR = \"/trinity/home/team06/workspace/mikhail_workspace/rag_project\"\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "sys.path.insert(0, BASE_DIR)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "from src.Reader import LLM_Model\n",
    "from src.utils import ReaderMetrics, save_reader_trial_log, prepare_reader_configs, load_benchmarks_df\n",
    "from src.utils import evaluate_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! TO CHANGE !!!\n",
    "TRIAL = 6\n",
    "BENCHMARKS_MAXSIZE = 500\n",
    "BENCHMARKS_INFO = {'mtssquad': {'table': 'v1'}}\n",
    "\n",
    "READER_PARAMS = {\n",
    "    'prompts': {\n",
    "        \"assistant\": \"Отвечай на вопросы, используя информацию из текстов в списке ниже:\",\n",
    "        \"system\": \"Ты вопросно-ответная система. Все ответы генерируй на русском языке. По вопросам отвечай кратко, чётко и конкретно. Не генерируй излишнюю информацию.\",\n",
    "    },\n",
    "    'gen': {'max_new_tokens': 512, 'eos_token_id': 79097},\n",
    "    'data_operate': {'batch_size': 1, 'num_workers':8}\n",
    "    }\n",
    "\n",
    "BERTSCORE_MODEL_PATH = \"ru_electra_medium\"\n",
    "# !!! TO CHANGE !!!\n",
    "\n",
    "ADDITIONAL_PARAMS = {\n",
    "    'unrel_c_mltp': 6,\n",
    "    'shuffle_contexts': True\n",
    "}\n",
    "\n",
    "SAVE_LOGDIR = f'./logs/trial{TRIAL}'\n",
    "SAVE_HYPERPARAMS = f'{SAVE_LOGDIR}/hyperparams.json'\n",
    "SAVE_READERCACHE = f'{SAVE_LOGDIR}/reader_cache.json'\n",
    "SAVE_RETRIEVERCACHE = f'{SAVE_LOGDIR}/retriever_cache.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "banchmarks_path = {}\n",
    "for name, version in BENCHMARKS_INFO.items():\n",
    "    banchmarks_path[name] = {\n",
    "        'table': f\"{BASE_DIR}/data/{name}/tables/{version['table']}/benchmark.csv\",\n",
    "        'chunked_docs': f\"{BASE_DIR}/data/{name}/tables/{version['table']}/chunked_docs.csv\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df = load_benchmarks_df(banchmarks_path, BENCHMARKS_MAXSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteor...\n",
      "Loading ExactMatch\n"
     ]
    }
   ],
   "source": [
    "reader_config = prepare_reader_configs(READER_PARAMS)\n",
    "reader_metrics = ReaderMetrics(base_dir=BASE_DIR, model_path=BERTSCORE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [04:08<00:00, 62.23s/it]\n"
     ]
    }
   ],
   "source": [
    "READER = LLM_Model(reader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "READER.config.data_operate.batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtssquad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/tmp/ipykernel_3017973/3197391923.py:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  selected_unrelevant_chunk_ids = random.sample(unrelevant_chunk_ids, ADDITIONAL_PARAMS['unrel_c_mltp'] * len(cur_relevant_chunk_ids))\n",
      "100%|██████████| 500/500 [00:00<00:00, 1893.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare raw unrelevant/relevant contexts proportion\n",
    "raw_contexts = {}\n",
    "retriever_cache = {}\n",
    "for name in banchmarks_path.keys():\n",
    "    print(name)\n",
    "    cur_chunked_df = pd.read_csv(banchmarks_path[name]['chunked_docs'], sep=';')\n",
    "    cur_chunked_df['metadata'] = cur_chunked_df['metadata'].map(lambda v: ast.literal_eval(v))\n",
    "    chunks_dict = {cur_chunked_df['metadata'][i]['chunk_id']: cur_chunked_df['chunks'][i] for i in range(cur_chunked_df.shape[0])}\n",
    "    all_chunk_ids = set(chunks_dict.keys())\n",
    "\n",
    "    raw_contexts[name] = []\n",
    "    retriever_cache[name] = []\n",
    "    for i in tqdm(range(benchmarks_df[name].shape[0])):\n",
    "        cur_relevant_chunk_ids = set(benchmarks_df[name]['chunk_ids'][i])\n",
    "        unrelevant_chunk_ids = all_chunk_ids.difference(cur_relevant_chunk_ids)\n",
    "        \n",
    "        selected_unrelevant_chunk_ids = random.sample(unrelevant_chunk_ids, ADDITIONAL_PARAMS['unrel_c_mltp'] * len(cur_relevant_chunk_ids))\n",
    "        \n",
    "        selected_chunk_ids = list(cur_relevant_chunk_ids) + selected_unrelevant_chunk_ids\n",
    "        if ADDITIONAL_PARAMS['shuffle_contexts']:\n",
    "            random.shuffle(selected_chunk_ids)\n",
    "        selected_contexts = [chunks_dict[idx] for idx in selected_chunk_ids]\n",
    "        \n",
    "        \n",
    "        raw_contexts[name].append(selected_contexts)\n",
    "        retriever_cache[name].append(selected_chunk_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = {name: [reader_config.prompts.assistant + \"\\n\\n\" + \"\\n\\n\".join([f'{i+1}. {doc}' for i, doc in enumerate(docs)]) \n",
    "                   for docs in contexts] for name, contexts in raw_contexts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/trinity/home/team06/workspace/mikhail_workspace/mikhail_venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/trinity/home/team06/workspace/mikhail_workspace/mikhail_venv/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  3%|▎         | 15/500 [00:55<34:18,  4.24s/it, BLEU2=0.245, BLEU1=0.303, ExactMatch=0, METEOR=0.516, BertScore=nan]Token indices sequence length is longer than the specified maximum sequence length for this model (1580 > 1512). Running this sequence through the model will result in indexing errors\n",
      "  3%|▎         | 16/500 [00:58<30:23,  3.77s/it, BLEU2=0.25, BLEU1=0.306, ExactMatch=0, METEOR=0.514, BertScore=nan] Token indices sequence length is longer than the specified maximum sequence length for this model (1596 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 10%|█         | 51/500 [02:54<24:34,  3.28s/it, BLEU2=0.332, BLEU1=0.393, ExactMatch=0.0784, METEOR=0.571, BertScore=nan]Token indices sequence length is longer than the specified maximum sequence length for this model (1544 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 27%|██▋       | 134/500 [09:38<18:18,  3.00s/it, BLEU2=0.281, BLEU1=0.341, ExactMatch=0.0373, METEOR=0.537, BertScore=nan]  Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 29%|██▉       | 146/500 [10:16<18:12,  3.09s/it, BLEU2=0.3, BLEU1=0.362, ExactMatch=0.0411, METEOR=0.551, BertScore=nan]  Token indices sequence length is longer than the specified maximum sequence length for this model (1635 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 30%|██▉       | 148/500 [10:30<32:27,  5.53s/it, BLEU2=0.298, BLEU1=0.36, ExactMatch=0.0405, METEOR=0.551, BertScore=nan]Token indices sequence length is longer than the specified maximum sequence length for this model (1637 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 31%|███       | 153/500 [11:17<36:36,  6.33s/it, BLEU2=0.291, BLEU1=0.352, ExactMatch=0.0392, METEOR=0.542, BertScore=nan]  Token indices sequence length is longer than the specified maximum sequence length for this model (1533 > 1512). Running this sequence through the model will result in indexing errors\n",
      " 38%|███▊      | 189/500 [15:23<49:01,  9.46s/it, BLEU2=0.272, BLEU1=0.335, ExactMatch=0.0317, METEOR=0.524, BertScore=nan] Token indices sequence length is longer than the specified maximum sequence length for this model (1617 > 1512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 500/500 [36:51<00:00,  4.42s/it, BLEU2=0.304, BLEU1=0.375, ExactMatch=0.028, METEOR=0.565, BertScore=nan]   \n"
     ]
    }
   ],
   "source": [
    "reader_scores, reader_cache = evaluate_reader(benchmarks_df, READER, reader_metrics, contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_reader_trial_log(SAVE_LOGDIR, reader_scores, SAVE_HYPERPARAMS, SAVE_READERCACHE, \n",
    "                      reader_cache, BENCHMARKS_INFO, BENCHMARKS_MAXSIZE, READER_PARAMS, ADDITIONAL_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_RETRIEVERCACHE, 'w', encoding='utf-8') as fd:\n",
    "    fd.write(json.dumps(retriever_cache, indent=1, ensure_ascii=False))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikhail_venv",
   "language": "python",
   "name": "mikhail_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
