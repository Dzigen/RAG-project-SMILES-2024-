{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "BASE_DIR = \"/home/dzigen/Desktop/Projects/rag_project\"\n",
    "sys.path.insert(0, BASE_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "random.seed(42)\n",
    "\n",
    "from src.llm_agent.agent_connector import AgentConnectorConfig, AgentConnector\n",
    "from src.utils import ReaderMetrics\n",
    "\n",
    "BENCHMARK_PATH = \"/home/dzigen/Desktop/Projects/rag_project/data/mtssquad/tables/v3/benchmark.csv\"\n",
    "CHUNKED_DOCS_PATH = \"/home/dzigen/Desktop/Projects/rag_project/data/mtssquad/tables/v3/chunked_docs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'version': 1,\n",
    "    'num_samples': 500,\n",
    "    'num_contexts': 5,\n",
    "    'system_prompt': \"Ты AI-асситент, который помогает решать пользовательские вопросы.\",\n",
    "    \"item_format\": \"- [{score}] {document}\",\n",
    "    \"user_prompt\": 'Ответь на вопрос, используя доступную информацию из текстов в списке ниже. Каждому тексту в начале в квадратных скобках поставлена в соответствие вещественная оценка его релевантности по отношению к вопросу: в диапозоне от 0.0 (текст не подходит для генерации ответа на его основе) до 1.0 (текст подходит для генерации ответа на его основе). Используй эту информацию. Выбирай тексты c достаточно высокими оценками релевантности. Если на основании указанных оценок в списке нет достаточно релевантных текстов для генерации ответов на их основе, то сгенерируй следующий ответ: \"У меня нет ответа на ваш вопрос.\". Ответы генерируй только на русском языке. Не дублируй вопрос в ответе. Сгенерируй только ответ на указанный вопрос. Не генерируй ничего лишнего.',\n",
    "    \"prompt_format\": \"{user_p}\\n\\nДоступная информация:\\n{cnt_list}\\n\\nВопрос:\\n{q}\\n\\nОтвет:\\n\",\n",
    "    'scores': {'rel': 1.0, 'unrel': 0.0},\n",
    "    'gen_strat': {'max_new_tokens': 1024},\n",
    "    'stub_answer': \"У меня нет ответа на ваш вопрос.\"\n",
    "}\n",
    "\n",
    "PARAMS_SAVE_NAME = 'hyperp.json'\n",
    "GEN_ANSW_SAVE_NAME = 'generation_info.json'\n",
    "SCORES_SAVE_NAME = 'scores.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение к агенту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentConnector.open(AgentConnectorConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.generate(\"Сколько будет 2 + 2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формируем список контекстов для каждого запроса со скорами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_df = pd.read_csv(CHUNKED_DOCS_PATH, sep=';')\n",
    "\n",
    "benchmark_df = pd.read_csv(BENCHMARK_PATH, sep=';')\n",
    "benchmark_df['chunk_ids'] = benchmark_df['chunk_ids'].apply(lambda v: ast.literal_eval(v)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 19437.33it/s]\n"
     ]
    }
   ],
   "source": [
    "CONTEXTS_LIST_IDS = []\n",
    "for i in tqdm(range(PARAMS['num_samples'])):\n",
    "    rel_id = benchmark_df['chunk_ids'][i][0]\n",
    "    cur_list_ids = []\n",
    "\n",
    "    while len(cur_list_ids) != PARAMS['num_contexts']:\n",
    "        unrel_context_id = random.randint(0, chunks_df.shape[0]-1)\n",
    "\n",
    "        if chunks_df['chunk_id'][unrel_context_id] == rel_id:\n",
    "            continue        \n",
    "\n",
    "        prep_cntx = (PARAMS['scores']['unrel'], chunks_df['chunk_id'][unrel_context_id])\n",
    "        if prep_cntx not in cur_list_ids:\n",
    "            cur_list_ids.append(prep_cntx)\n",
    "\n",
    "    CONTEXTS_LIST_IDS.append(cur_list_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'd764509cd8bbeca063ad039f783937fd'),\n",
       " (0.0, '3296e4d68127ee5f3604f78d11642396'),\n",
       " (0.0, 'fce1f4f018a5a48dee1a0d7849189375'),\n",
       " (0.0, '50b5aa882912e4987405ed1551595f4f'),\n",
       " (0.0, 'b9a708c0396d19d2a3621bffb4744f37')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXTS_LIST_IDS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовим промпт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 262.54it/s]\n"
     ]
    }
   ],
   "source": [
    "USER_PROMPTS = []\n",
    "for i in tqdm(range(len(CONTEXTS_LIST_IDS))):\n",
    "    documents_list = '\\n'.join(list(map(lambda v: PARAMS['item_format'].format(\n",
    "        score=v[0], document=chunks_df[chunks_df['chunk_id'] == v[1]]['chunks'].to_list()[0]), CONTEXTS_LIST_IDS[i])))\n",
    "\n",
    "    USER_PROMPTS.append( PARAMS['prompt_format'].format(user_p=PARAMS['user_prompt'], cnt_list=documents_list, q=benchmark_df['question'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответь на вопрос, используя доступную информацию из текстов в списке ниже. Каждому тексту в начале в квадратных скобках поставлена в соответствие вещественная оценка его релевантности по отношению к вопросу: в диапозоне от 0.0 (текст не подходит для генерации ответа на его основе) до 1.0 (текст подходит для генерации ответа на его основе). Используй эту информацию. Выбирай тексты c достаточно высокими оценками релевантности. Если на основании указанных оценок в списке нет достаточно релевантных текстов для генерации ответов на их основе, то сгенерируй следующий ответ: \"У меня нет ответа на ваш вопрос.\". Ответы генерируй только на русском языке. Не дублируй вопрос в ответе. Сгенерируй только ответ на указанный вопрос. Не генерируй ничего лишнего.\n",
      "\n",
      "Доступная информация:\n",
      "- [0.0] В рамках прямого финансирования: банк предоставляет компаниям малого и среднего бизнеса кредитно-гарантийную поддержку, в том числе по Программе стимулирования кредитования субъектов МСП ( Программа 6,5 ). Для среднего бизнеса ставки по кредитам начинаются с 9,6 процентов годовых, для малого - с 10,6. Предпринимателям доступно кредитование на сумму от 1 млн до 500 млн рублей. Помимо кредитных продуктов, МСП Банк предоставляет субъектам МСП гарантийную поддержку. Банк предоставляет гарантии в рамках 44-ФЗ и 223-ФЗ, а также выдаёт прямые гарантии для получения субъектами МСП банковских кредитов при недостаточности залогового обеспечения в рамках Национальной гарантийной системы.\n",
      "- [0.0] Бизнес или неправительственные организации могут иметь разную мотивацию, чтобы предлагать продукты или услуги на основе принципа скользящей шкалы. Например, благотворительность с пользу тех, кто имеет меньше возможностей позволить себе данный продукт или услугу, потенциальная возможность для налоговых вычетов при предложении услуг, таких как благотворительность, возможность даже частичные доходы, чтобы внести свой вклад в положительный финансовый баланс, желание сохранить давних клиентов или привлечь дополнительных клиентов, которые могут прийти, благодаря рекомендациям от давних клиентов.\n",
      "- [0.0] Модернизация подвергается критике, в основном потому, что часто смешивается с вестернизацией. В этой модели модернизации общества требуется уничтожение культуры коренных народов и замена её на более западную культуру. Сторонники теории модернизации обычно рассматривают только западное общество как подлинно современное, утверждая, что другие общества в сравнении с ним являются примитивными. Эта точка зрения сводит немодернизированные общества к неполноценным, даже если их уровень жизни не уступает уровню западных обществ. Противники этой точки зрения утверждают, что модерновость не зависит от культуры и может быть адаптирована к любому обществу. Япония приводится в качестве примера обеими сторонами. Некоторые рассматривают её как доказательство того, что современный образ жизни может существовать вне западного общества. Другие утверждают, что Япония стала заметно более западной в результате её модернизации.\n",
      "- [0.0] Конец 1970-х и 1980-е годы охарактеризовались усталостью от концептуального искусства и минимализма и возвратом интереса к изобразительности, цвету и фигуративности (расцвет таких движений как Новые дикие ). На середину 1980-х приходится время подъёма движений, активно использующих образы массовой культуры — кэмпизм, искусство ист-виллиджа, набирает силы нео-поп. К этому же времени относится расцвет фотографии в искусстве — всё больше художников начинают обращаться к ней как к средству художественного выражения.\n",
      "- [0.0] Итак, с эмпирической точки зрения относительная всеобщность и необходимость законов нашего познания есть результат единообразных воздействий опыта на нашу физико-психическую организацию, породивших такую ассоциационную связь между известными элементами сознания, которая стала неразрывной благодаря аккумулированному наследственному опыту, индивидуальной привычке и влиянию окружающей социальной среды. Если так называемые всеобщие и необходимые законы познания отличаются лишь высокой степенью вероятности, а не безусловной достоверностью, то ничто не препятствует нам допускать возможность их изменения, хотя бы и очень медленного, что и высказывают Спенсер и другие эволюционисты (см. Челпанов, Г. И., Проблема восприятия пространства , ч. II, 1904, стр. 215).\n",
      "\n",
      "Вопрос:\n",
      "По просьбе Мадонны поменяли аранжировщика на более опытного?\n",
      "\n",
      "Ответ:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(USER_PROMPTS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./logs/v{PARAMS['version']}/user_prompts.json\", 'w', encoding='utf-8') as fp:\n",
    "    fp.write(json.dumps(USER_PROMPTS, ensure_ascii=False, indent=1))\n",
    "\n",
    "# сохраняем конфигурацию эксперимента\n",
    "with open(f\"./logs/v{PARAMS['version']}/{PARAMS_SAVE_NAME}\", 'w', encoding='utf-8') as fp:\n",
    "    fp.write(json.dumps(PARAMS, ensure_ascii=False, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерируем ответы на вопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_answers = []\n",
    "display_iter = 2\n",
    "for i in tqdm(range(len(USER_PROMPTS))):\n",
    "    pred_answer = agent.generate(user_prompt=USER_PROMPTS[i], system_prompt=PARAMS['system_prompt'], gen_strategy=PARAMS['gen_strat'])\n",
    "    generate_answers.append(pred_answer)\n",
    "\n",
    "    if i % display_iter == 0:\n",
    "        print(f\"\\n[{i}]: \\nGEN: {pred_answer}\\nGOLD: {benchmark_df['answer'][i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оцениваем качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./logs/v1/generated_output.json','r', encoding='utf8') as fd:\n",
    "    predicted_answers = list(map(lambda v: v[0], json.loads(fd.read())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Meteor...\n",
      "Loading ExactMatch\n"
     ]
    }
   ],
   "source": [
    "metrics = ReaderMetrics(base_dir=\"/home/dzigen/Desktop/Projects/rag_project\", model_path='ru_electra_medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/dzigen/miniconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dzigen/miniconda3/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 500/500 [00:39<00:00, 12.60it/s, BLEU2=1, BLEU1=1, ExactMatch=1, METEOR=0.999, BertScore=nan, Levenshtain=0, ROUGEL=nan]\n",
      "/home/dzigen/miniconda3/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "target_scores = {\n",
    "    'BLEU2': [], 'BLEU1': [],\n",
    "    'ExactMatch': [],'METEOR': [],\n",
    "    'BertScore': [],\n",
    "    'Levenshtain': [],\n",
    "    'ROUGEL': []}\n",
    "\n",
    "stub_scores = {\n",
    "    'BLEU2': [], 'BLEU1': [],\n",
    "    'ExactMatch': [],'METEOR': [],\n",
    "    'BertScore': [],\n",
    "    'Levenshtain': [],\n",
    "    'ROUGEL': []}\n",
    "\n",
    "show_step = 10\n",
    "\n",
    "process = tqdm(range(PARAMS['num_samples']))\n",
    "target_answers =  benchmark_df['answer'].to_list()[:PARAMS['num_samples']]\n",
    "tmp_stub_pred_answers = []\n",
    "for i in process:\n",
    "    \n",
    "    predicted_answer = predicted_answers[i]\n",
    "    target_answer = target_answers[i]\n",
    "\n",
    "    target_scores['BLEU1'] += metrics.bleu1([predicted_answer], [target_answer])\n",
    "    target_scores['BLEU2'] += metrics.bleu2([predicted_answer], [target_answer])\n",
    "    target_scores['ExactMatch'] += metrics.exact_match([predicted_answer], [target_answer])\n",
    "    target_scores['METEOR'] += metrics.meteor([predicted_answer], [target_answer])\n",
    "    target_scores['Levenshtain'] += metrics.levenshtain_score([predicted_answer], [target_answer])\n",
    "    target_scores['ROUGEL'] += metrics.rougel([predicted_answer], [target_answer])\n",
    "\n",
    "\n",
    "    stub_pred_answer = predicted_answer[-len(PARAMS['stub_answer']):]\n",
    "    tmp_stub_pred_answers.append(stub_pred_answer)\n",
    "\n",
    "    stub_scores['BLEU1'] += metrics.bleu1([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "    stub_scores['BLEU2'] += metrics.bleu2([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "    stub_scores['ExactMatch'] += metrics.exact_match([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "    stub_scores['METEOR'] += metrics.meteor([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "    stub_scores['Levenshtain'] += metrics.levenshtain_score([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "    target_scores['ROUGEL'] += metrics.rougel([stub_pred_answer], [PARAMS['stub_answer']])\n",
    "            \n",
    "    if i % show_step == 0:\n",
    "        process.set_postfix({m_name: np.mean(score) for m_name, score in stub_scores.items()})\n",
    "\n",
    "target_scores = {m_name: round(float(np.mean(score)), 5) for m_name, score in target_scores.items()}\n",
    "target_scores['BertScore'] = metrics.bertscore(predicted_answers, target_answers)\n",
    "\n",
    "stub_scores = {m_name: round(float(np.mean(score)), 5) for m_name, score in stub_scores.items()}\n",
    "stub_scores['BertScore'] = metrics.bertscore(tmp_stub_pred_answers, [PARAMS['stub_answer']]*len(tmp_stub_pred_answers))\n",
    "stub_scores['elapsed_time_sec'] = round(float(process.format_dict[\"elapsed\"]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./logs/v{PARAMS['version']}/{SCORES_SAVE_NAME}\", 'w', encoding='utf-8') as fp:\n",
    "    fp.write(json.dumps({'target_answers': target_scores, 'stub_answers': stub_scores}, ensure_ascii=False, indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
