{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "LOAD_PATH = '../../data/mtssquad/base_dataset.csv'\n",
    "SAVE_TABLE_PATH = '../../data/mtssquad/tables/v1/chunked_docs.csv'\n",
    "SAVE_BENCHMARK_PATH = '../../data/mtssquad/tables/v1/benchmark.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_stat(df):\n",
    "    print(\"===Статистика по исходному датасету===\")\n",
    "    print(\"Количество строк в датасете: \", df.shape[0])\n",
    "    print(\"Количество уникальных context-текстов: \", len(df['context'].unique()))\n",
    "    print(\"Количество уникальных question-текстов: \", len(df['question'].unique()))\n",
    "    print(\"Количество уникальных answer-текстов: \", len(df['answer'].unique()))\n",
    "\n",
    "def get_hash(value: str, hash_len: int = 10) -> float:\n",
    "    return hash(value) % (10 ** hash_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(LOAD_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Удаление дубликатов (questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_filtered_df = base_df.drop_duplicates(subset=['question']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Статистика по исходному датасету===\n",
      "Количество строк в датасете:  49908\n",
      "Количество уникальных context-текстов:  9031\n",
      "Количество уникальных question-текстов:  49908\n",
      "Количество уникальных answer-текстов:  46942\n"
     ]
    }
   ],
   "source": [
    "print_df_stat(q_filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Удаление дубликатов (answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_filtered_df = q_filtered_df.drop_duplicates(subset=['answer']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Статистика по исходному датасету===\n",
      "Количество строк в датасете:  46942\n",
      "Количество уникальных context-текстов:  9028\n",
      "Количество уникальных question-текстов:  46942\n",
      "Количество уникальных answer-текстов:  46942\n"
     ]
    }
   ],
   "source": [
    "print_df_stat(aq_filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Формирование таблицы с чанками для базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46942/46942 [00:01<00:00, 25917.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all chunks:  46942\n",
      "unique chunks:  9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Создание таблицы для формирования бд\n",
    "tmp_data = []\n",
    "chunk_ids_seq = []\n",
    "\n",
    "unique_chunk_ids = []\n",
    "\n",
    "for i in tqdm(range(aq_filtered_df.shape[0])):\n",
    "    chunk = aq_filtered_df['context'][i]\n",
    "    chunk_id = get_hash(chunk, hash_len=10)\n",
    "    chunk_ids_seq.append(chunk_id)\n",
    "\n",
    "    if chunk_id not in unique_chunk_ids:\n",
    "        document = [chunk, {'doc_id': chunk_id, 'chunk_id': chunk_id, \n",
    "                            'prev_chunk_id': None, 'next_chunk_id': None}]\n",
    "        unique_chunk_ids.append(chunk_id)\n",
    "        tmp_data.append(document)\n",
    "\n",
    "aq_filtered_df['chunk_id'] = chunk_ids_seq\n",
    "table_df = pd.DataFrame(tmp_data, columns=['chunks', 'metadata'])\n",
    "\n",
    "print(\"all chunks: \", aq_filtered_df['context'].shape[0])\n",
    "print(\"unique chunks: \", len(unique_chunk_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_df.to_csv(SAVE_TABLE_PATH, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование датасета с зависимостями на таблицу чанков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46942/46942 [00:01<00:00, 44401.83it/s]\n"
     ]
    }
   ],
   "source": [
    "tmp_data = {}\n",
    "for i in tqdm(range(aq_filtered_df.shape[0])):\n",
    "    qst_hash = get_hash(aq_filtered_df['question'][i])\n",
    "    if qst_hash in tmp_data.keys():\n",
    "        print(qst_hash, aq_filtered_df['question'][i])\n",
    "        tmp_data[qst_hash]['chunk_ids'].append(aq_filtered_df['chunk_id'][i])\n",
    "        tmp_data[qst_hash]['contexts'].append(aq_filtered_df['context'][i])\n",
    "    else:\n",
    "        tmp_data[qst_hash] = {'question': aq_filtered_df['question'][i], 'answer': aq_filtered_df['answer'][i], \n",
    "                              'chunk_ids': [aq_filtered_df['chunk_id'][i]], 'contexts': [aq_filtered_df['context'][i]]}\n",
    "\n",
    "    tmp_data[qst_hash]['chunk_ids'] = list(set(tmp_data[qst_hash]['chunk_ids']))\n",
    "    tmp_data[qst_hash]['contexts'] = list(set(tmp_data[qst_hash]['contexts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df = pd.DataFrame(list(tmp_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 46942})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(list(map(len, benchmark_df['chunk_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_df.to_csv(SAVE_BENCHMARK_PATH, sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
