{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "185fa439-7815-459d-aaf0-97041a23b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import  pipeline\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4a1f046-e6c2-4bbb-a559-3b970e14161a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d72dec6c-e42f-4658-8aa8-a46edee939bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdbf3650-99e7-4c9c-ae56-5beef2370723",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_MODEL_PATH = '/trinity/home/team06/workspace/mikhail_workspace/rag_project/models/vikhr_7B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6c5e541-8809-4e6c-8a4a-365db2dae691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:50<00:00, 27.66s/it]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Vikhrmodels/Vikhr-7B-instruct_0.4\",\n",
    "                                             device_map=\"auto\",\n",
    "                                             attn_implementation=\"flash_attention_2\",\n",
    "                                             torch_dtype=torch.bfloat16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vikhrmodels/Vikhr-7B-instruct_0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a6e902-784d-4106-848e-7b64d693668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(SAVE_MODEL_PATH)\n",
    "tokenizer.save_pretrained(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935530cd-a4e7-4a1e-b761-ecbdb2a7079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff30fd5a-475a-4fa0-9a57-da0df0bc2473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    prompt:\n",
      "Кто такой Михаил Меньщиков?\n",
      "<s><|im_start|>system\n",
      "Ты вопросно-ответная система. Отвечай чётко и кратко без лишних подробностей.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Список текстов, на основе которых необходимо генерировать ответ:\n",
      "1.Михаил Меньщиков - программный инженер из небольшого городка в Республике Карелия.\n",
      "2.Михаил Меньщиков известен своими достижениями области разработки программного обеспечения с интеграцией технологий машинного и глубокого обучения.<|im_end|>\n",
      "<|im_start|>user\n",
      "Кто такой Михаил Меньщиков?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "    response:\n",
      "Михаил Меньщиков - инженер-программист из небольшого городка в Республике Карелия. Он известен своими достижениями в области разработки программного обеспечения, особенно в интеграции технологий машинного и глубокого обучения.\n",
      "--------------------------------------------------\n",
      "    prompt:\n",
      "Чем известен Михаил Меньщиков?\n",
      "<s><|im_start|>system\n",
      "Ты вопросно-ответная система. Отвечай чётко и кратко без лишних подробностей.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Список текстов, на основе которых необходимо генерировать ответ:\n",
      "1.Михаил Меньщиков - программный инженер из небольшого городка в Республике Карелия.\n",
      "2.Михаил Меньщиков известен своими достижениями области разработки программного обеспечения с интеграцией технологий машинного и глубокого обучения.<|im_end|>\n",
      "<|im_start|>user\n",
      "Чем известен Михаил Меньщиков?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "    response:\n",
      "Михаил Меньщиков известен своими достижениями в области разработки программного обеспечения с интеграцией технологий машинного и глубокого обучения.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "prompts = [\n",
    "    \"Кто такой Михаил Меньщиков?\", \"Чем известен Михаил Меньщиков?\"]\n",
    "\n",
    "def test_inference(prompt):\n",
    "    prompt = pipe.tokenizer.apply_chat_template([{'role': 'system', 'content': 'Ты вопросно-ответная система. Отвечай чётко и кратко без лишних подробностей.'},\n",
    "                                                 {'role': 'assistant', 'content': \"\"\"Список текстов, на основе которых необходимо генерировать ответ:\\n1.Михаил Меньщиков - программный инженер из небольшого городка в Республике Карелия.\\n2.Михаил Меньщиков известен своими достижениями области разработки программного обеспечения с интеграцией технологий машинного и глубокого обучения.\"\"\"},\n",
    "                                                 {\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    print(prompt)\n",
    "    outputs = pipe(prompt, max_new_tokens=512, num_beams=5, eos_token_id=79097, early_stopping=True)\n",
    "    return outputs[0]['generated_text'][len(prompt):].strip()\n",
    "\n",
    "\n",
    "for prompt in prompts:\n",
    "    print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(prompt)}\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a44db-5832-4699-a4a3-c576cec8fc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mikhail_venv",
   "language": "python",
   "name": "mikhail_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
